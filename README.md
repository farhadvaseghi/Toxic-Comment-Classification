
# Toxic Comment Classification Using TensorFlow
<p align="center">
<kbd>
   <img align="center" src="https://github.com/TomRSavage/ParticleSwarm/blob/master/Sty.gif" width="700" height="500">
</kbd>
</p>

## Description 
Online forums and social media platforms have provided individuals with the means to put forward their thoughts and freely express their opinion on various issues and incidents. In some cases, these online comments contain explicit language which may hurt the readers. Comments containing explicit language can be classified into myriad categories such as Toxic, Severe Toxic, Obscene, Threat, Insult, and Identity Hate.To protect users from being exposed to offensive language on online forums or social media sites, companies have started flagging comments and blocking users who are found guilty of using unpleasant language. In this project we are going to implement a model to could classify all of these comments.

## Dataset
You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:
* toxic
* severe_toxic
* obscene
* threat
* insult
* identity_hate

Link to dataset is as follows:

[link](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data)

## Result
We tested our model on an online platform named "Gradio".Gradio is the fastest way to demo our machine learning model with a friendly web interface so that anyone can use it, anywhere!
<p align="center">
<kbd>
   <img align="center" src="https://github.com/TomRSavage/ParticleSwarm/blob/master/Sty.gif" width="700" height="500">
</kbd>
</p>